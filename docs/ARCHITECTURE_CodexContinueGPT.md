# ğŸ§  CodexContinueGPT v1 - Architecture Blueprint

ğŸ“… Date: 2025-04-30  
ğŸ‘¨â€âœˆï¸ Maintainer: Captain MO + CodexContinue Assistant  

---

## ğŸ¯ Purpose

CodexContinueGPT v1 is the intelligence core of the CodexContinue platform.  
It combines multi-LLM chat orchestration, memory routing, plugin/tool calling, and fast developer response generation.

---

## ğŸ§© System Overview

+---------------------+ | Streamlit UI | <--- User Input / Reply Stream +---------------------+ | v +---------------------+ | FastAPI Router | | (/chat, /memory) | +---------------------+ | v +-------------------------+ | ğŸ§  MemoryManager | --> Session and history control +-------------------------+ | v +-------------------------+ | ğŸ¤– LLM Gateway (Brain) | | - OpenAI / Azure | | - Ollama / TabbyML | +-------------------------+ | v +-------------------------+ | ğŸ”Œ Tool/Plugin System | | - Shell Tools | | - File/Code Utils | | - Data Analysis Tools | +-------------------------+

yaml
Copy
Edit

---

## ğŸ“¦ Core Modules

### 1. `app/brain/`
- `memory_manager.py`: Handles per-session message storage
- `storage.py`: Future DB/Redis swap backend

### 2. `app/routes/`
- `chat.py`: Central async router for all user input
- `memory.py`: Manual control over memory sessions

### 3. `app/services/`
- `llm_service.py`: Handles model-specific calls
- `tool_runner.py`: (Planned) Executes shell/file commands

---

## ğŸ” LLM Flow (Async)

1. UI input triggers `/chat` POST
2. Message is stored in `MemoryManager`
3. LLM selected based on `MODEL_PROVIDER`
4. LLM response fetched and parsed
5. Reply saved into memory and returned

---

## ğŸš€ Roadmap Features

- [ ] LLM selector from `.env`: `openai`, `azure`, `ollama`, `tabbyml`
- [ ] Streaming response support (via SSE or WebSocket)
- [ ] User-uploaded file tools (e.g., CSV summary, file Q&A)
- [ ] Tool-calling (plugin-style structure)
- [ ] Memory export/import (JSON)

---

## ğŸ§  Memory Options

| Type        | Description                       |
|-------------|-----------------------------------|
| Short-term  | In-memory dict (current default)  |
| Long-term   | File-based or Redis (TBD)         |
| Session     | One per user (UUID from Streamlit)|

---

> ğŸ›¡ï¸ This architecture will grow with you.  
> All future agents, copilots, and codexes will respect this contract.

